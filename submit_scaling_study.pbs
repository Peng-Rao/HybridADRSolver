#!/bin/bash
#PBS -N adr_scaling_study
#PBS -l select=1:ncpus=28
#PBS -l walltime=24:00:00
#PBS -q cpu
#PBS -A Hybrid-Parallelism-ADR-Solver-PDE2025
#PBS -m abe
#PBS -M peng.rao@mail.polimi.it

#===============================================================================
# Setup
#===============================================================================

cd ${PBS_O_WORKDIR:-$(pwd)}

TIMESTAMP=$(date +%Y%m%d_%H%M%S)
LOG_DIR="logs_scaling"
mkdir -p ${LOG_DIR}
LOG_FILE="${LOG_DIR}/scaling_${PBS_JOBID:-local}_${TIMESTAMP}.log"

RESULTS_DIR="results_scaling_${TIMESTAMP}"
mkdir -p ${RESULTS_DIR}

exec > >(tee -a "${LOG_FILE}") 2>&1

echo "==============================================================================="
echo "SCALING BENCHMARK - OpenMPI"
echo "==============================================================================="
echo "Job ID: ${PBS_JOBID}"
echo "Date: $(date)"
echo "Results Dir: ${RESULTS_DIR}"
echo "==============================================================================="

#-------------------------------------------------------------------------------
# Environment Setup
#-------------------------------------------------------------------------------
echo ""
echo "MPI Configuration:"
mpirun --version | head -3
echo ""

ulimit -s unlimited

#===============================================================================
# Build
#===============================================================================

BUILD_DIR="build"
EXECUTABLE="${BUILD_DIR}/scaling_study"
REBUILD_REQUIRED=false

if [ ! -f "$EXECUTABLE" ]; then
    REBUILD_REQUIRED=true
else
    NEWEST_SOURCE=$(find . -maxdepth 2 \( -name "*.cpp" -o -name "*.h" -o -name "CMakeLists.txt" \) 2>/dev/null | xargs ls -t 2>/dev/null | head -n 1)
    if [ -n "$NEWEST_SOURCE" ] && [ "$NEWEST_SOURCE" -nt "$EXECUTABLE" ]; then
        REBUILD_REQUIRED=true
    fi
fi

if [ "$REBUILD_REQUIRED" = true ]; then
    echo "Building scaling benchmark..."
    mkdir -p ${BUILD_DIR}
    cd ${BUILD_DIR}
    cmake .. -DCMAKE_BUILD_TYPE=Release
    make -j 28 scaling_study || exit 1
    cd ..
    echo "Build complete."
else
    echo "Binary is up to date."
fi

echo ""
echo "Library linking check (MPI libraries):"
ldd ${EXECUTABLE} | grep -E "mpi" | head -5
echo ""

#===============================================================================
# Benchmark Parameters
#===============================================================================

DIM=2
DEGREE=2
WARMUP=1
TRIALS=3

MIN_REF_STRONG=9
MAX_REF_STRONG=11

MIN_REF_WEAK=7
MAX_REF_WEAK=9

MPI_CMD="mpirun"

echo ""
echo "==============================================================================="
echo "Problem Size Estimates (2D Q2 elements)"
echo "==============================================================================="
echo "refs=9:  ~1.05M DoFs"
echo "refs=10: ~4.2M DoFs"
echo "refs=11: ~16.8M DoFs"
echo ""
echo "Selected range: refs ${MIN_REF_STRONG}-${MAX_REF_STRONG}"
echo "==============================================================================="

#===============================================================================
# PHASE 1: PURE MPI STRONG SCALING
#===============================================================================

echo ""
echo "==============================================================================="
echo "PHASE 1: PURE MPI STRONG SCALING"
echo "==============================================================================="
echo "Testing with 1 thread per MPI process"
echo "No binding (letting OS handle scheduling)"
echo ""

declare -a PURE_MPI_CONFIGS=(
    "1 1"
    "2 1"
    "4 1"
    "7 1"
    "14 1"
    "28 1"
)

for CONFIG in "${PURE_MPI_CONFIGS[@]}"; do
    read -r NRANKS NTHREADS <<< "$CONFIG"
    TOTAL_CORES=$((NRANKS * NTHREADS))
    CONFIG_NAME="pure_mpi_${NRANKS}"

    echo ""
    echo "-----------------------------------------------------------------------"
    echo "Pure MPI: ${NRANKS} processes × ${NTHREADS} thread = ${TOTAL_CORES} cores"
    echo "-----------------------------------------------------------------------"

    export TBB_NUM_THREADS=${NTHREADS}
    export OMP_NUM_THREADS=${NTHREADS}

    OUTPUT_PREFIX="${RESULTS_DIR}/strong_${CONFIG_NAME}"

    ${MPI_CMD} -np ${NRANKS} \
        ${EXECUTABLE} \
        --strong \
        --min-ref ${MIN_REF_STRONG} \
        --max-ref ${MAX_REF_STRONG} \
        --degree ${DEGREE} \
        --dim ${DIM} \
        --output "${OUTPUT_PREFIX}" \
        --threads ${NTHREADS} \
        --warmup ${WARMUP} \
        --trials ${TRIALS} \
        2>&1 | tee "${OUTPUT_PREFIX}.log"

    sleep 2
done

#===============================================================================
# PHASE 2: PURE THREADING SCALING
#===============================================================================

echo ""
echo "==============================================================================="
echo "PHASE 2: PURE THREADING SCALING"
echo "==============================================================================="
echo "Testing with 1 MPI process, varying threads"
echo ""

declare -a PURE_THREAD_CONFIGS=(
    "1 2"
    "1 4"
    "1 7"
    "1 14"
    "1 28"
)

for CONFIG in "${PURE_THREAD_CONFIGS[@]}"; do
    read -r NRANKS NTHREADS <<< "$CONFIG"
    TOTAL_CORES=$((NRANKS * NTHREADS))
    CONFIG_NAME="pure_thread_${NTHREADS}"

    echo ""
    echo "-----------------------------------------------------------------------"
    echo "Pure Threading: ${NRANKS} process × ${NTHREADS} threads = ${TOTAL_CORES} cores"
    echo "-----------------------------------------------------------------------"

    export TBB_NUM_THREADS=${NTHREADS}
    export OMP_NUM_THREADS=${NTHREADS}

    OUTPUT_PREFIX="${RESULTS_DIR}/strong_${CONFIG_NAME}"

    ${MPI_CMD} -np ${NRANKS} \
        ${EXECUTABLE} \
        --strong \
        --min-ref ${MIN_REF_STRONG} \
        --max-ref ${MAX_REF_STRONG} \
        --degree ${DEGREE} \
        --dim ${DIM} \
        --output "${OUTPUT_PREFIX}" \
        --threads ${NTHREADS} \
        --warmup ${WARMUP} \
        --trials ${TRIALS} \
        2>&1 | tee "${OUTPUT_PREFIX}.log"

    sleep 2
done

#===============================================================================
# PHASE 3: HYBRID CONFIGURATIONS
#===============================================================================

echo ""
echo "==============================================================================="
echo "PHASE 3: HYBRID ANALYSIS AT FIXED CORE COUNTS"
echo "==============================================================================="
echo "Comparing different MPI×Thread configurations at 14 and 28 total cores"
echo ""

declare -a HYBRID_14=(
    "14 1"
    "7 2"
    "2 7"
    "1 14"
)

declare -a HYBRID_28=(
    "28 1"
    "14 2"
    "7 4"
    "4 7"
    "2 14"
    "1 28"
)

echo "--- Testing 14 cores ---"
for CONFIG in "${HYBRID_14[@]}"; do
    read -r NRANKS NTHREADS <<< "$CONFIG"
    CONFIG_NAME="hybrid_${NRANKS}x${NTHREADS}"

    echo "  ${NRANKS} MPI × ${NTHREADS} threads"

    export TBB_NUM_THREADS=${NTHREADS}
    export OMP_NUM_THREADS=${NTHREADS}

    OUTPUT_PREFIX="${RESULTS_DIR}/hybrid14_${CONFIG_NAME}"

    ${MPI_CMD} -np ${NRANKS} \
        ${EXECUTABLE} \
        --strong \
        --min-ref ${MAX_REF_STRONG} \
        --max-ref ${MAX_REF_STRONG} \
        --degree ${DEGREE} \
        --dim ${DIM} \
        --output "${OUTPUT_PREFIX}" \
        --threads ${NTHREADS} \
        --warmup ${WARMUP} \
        --trials ${TRIALS} \
        2>&1 > "${OUTPUT_PREFIX}.log"

    sleep 1
done

echo ""
echo "--- Testing 28 cores ---"
for CONFIG in "${HYBRID_28[@]}"; do
    read -r NRANKS NTHREADS <<< "$CONFIG"
    CONFIG_NAME="hybrid_${NRANKS}x${NTHREADS}"

    echo "  ${NRANKS} MPI × ${NTHREADS} threads"

    export TBB_NUM_THREADS=${NTHREADS}
    export OMP_NUM_THREADS=${NTHREADS}

    OUTPUT_PREFIX="${RESULTS_DIR}/hybrid28_${CONFIG_NAME}"

    ${MPI_CMD} -np ${NRANKS} \
        ${EXECUTABLE} \
        --strong \
        --min-ref ${MAX_REF_STRONG} \
        --max-ref ${MAX_REF_STRONG} \
        --degree ${DEGREE} \
        --dim ${DIM} \
        --output "${OUTPUT_PREFIX}" \
        --threads ${NTHREADS} \
        --warmup ${WARMUP} \
        --trials ${TRIALS} \
        2>&1 > "${OUTPUT_PREFIX}.log"

    sleep 1
done

#===============================================================================
# PHASE 4: WEAK SCALING
#===============================================================================

echo ""
echo "==============================================================================="
echo "PHASE 4: WEAK SCALING (Pure MPI)"
echo "==============================================================================="
echo ""

for CONFIG in "${PURE_MPI_CONFIGS[@]}"; do
    read -r NRANKS NTHREADS <<< "$CONFIG"
    TOTAL_CORES=$((NRANKS * NTHREADS))
    CONFIG_NAME="weak_mpi_${NRANKS}"

    echo ""
    echo "-----------------------------------------------------------------------"
    echo "Weak Scaling: ${NRANKS} processes"
    echo "-----------------------------------------------------------------------"

    export TBB_NUM_THREADS=${NTHREADS}
    export OMP_NUM_THREADS=${NTHREADS}

    OUTPUT_PREFIX="${RESULTS_DIR}/${CONFIG_NAME}"

    ${MPI_CMD} -np ${NRANKS} \
        ${EXECUTABLE} \
        --weak \
        --min-ref ${MIN_REF_WEAK} \
        --max-ref ${MAX_REF_WEAK} \
        --degree ${DEGREE} \
        --dim ${DIM} \
        --output "${OUTPUT_PREFIX}" \
        --threads ${NTHREADS} \
        --warmup ${WARMUP} \
        --trials ${TRIALS} \
        2>&1 | tee "${OUTPUT_PREFIX}.log"

    sleep 2
done

#===============================================================================
# Combine Results
#===============================================================================

echo ""
echo "==============================================================================="
echo "Combining Results"
echo "==============================================================================="

COMBINED_PURE_MPI="${RESULTS_DIR}/combined_pure_mpi.csv"
COMBINED_PURE_THREAD="${RESULTS_DIR}/combined_pure_thread.csv"
COMBINED_HYBRID="${RESULTS_DIR}/combined_hybrid.csv"
COMBINED_WEAK="${RESULTS_DIR}/combined_weak.csv"
COMBINED_ALL="${RESULTS_DIR}/combined_all_results.csv"

combine_csv() {
    local output=$1
    shift
    local pattern=$1

    first_file=true
    for f in ${RESULTS_DIR}/${pattern}*.csv; do
        if [ -f "$f" ]; then
            if [ "$first_file" = true ]; then
                cat "$f" > ${output}
                first_file=false
            else
                tail -n +2 "$f" >> ${output}
            fi
        fi
    done

    if [ -f "${output}" ]; then
        echo "Created: ${output}"
    fi
}

combine_csv "${COMBINED_PURE_MPI}" "strong_pure_mpi_"
combine_csv "${COMBINED_PURE_THREAD}" "strong_pure_thread_"
combine_csv "${COMBINED_HYBRID}" "hybrid"
combine_csv "${COMBINED_WEAK}" "weak_"

first_file=true
for f in "${COMBINED_PURE_MPI}" "${COMBINED_PURE_THREAD}" "${COMBINED_HYBRID}" "${COMBINED_WEAK}"; do
    if [ -f "$f" ]; then
        if [ "$first_file" = true ]; then
            cat "$f" > ${COMBINED_ALL}
            first_file=false
        else
            tail -n +2 "$f" >> ${COMBINED_ALL}
        fi
    fi
done
echo "Created: ${COMBINED_ALL}"

#===============================================================================
# Generate Analysis Script
#===============================================================================

ANALYSIS_SCRIPT="${RESULTS_DIR}/analyze_scaling.py"

cat > ${ANALYSIS_SCRIPT} << 'PYTHON_EOF'
#!/usr/bin/env python3
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import sys
import os

plt.style.use('seaborn-v0_8-whitegrid')
plt.rcParams['figure.dpi'] = 150
plt.rcParams['font.size'] = 10

def load_data(filename):
    return pd.read_csv(filename)

def plot_strong_scaling_pure_mpi(df, output_dir):
    fig, axes = plt.subplots(2, 2, figsize=(12, 10))

    strong_df = df[(df['test_type'] == 'strong_scaling') & (df['n_threads'] == 1)].copy()

    if strong_df.empty:
        print("No pure MPI strong scaling data")
        return

    colors = {'matrix_based': 'tab:blue', 'matrix_free': 'tab:orange'}
    markers = {'matrix_based': 'o', 'matrix_free': 's'}

    for solver in ['matrix_based', 'matrix_free']:
        solver_df = strong_df[strong_df['solver_type'] == solver]
        if solver_df.empty:
            continue

        refs_list = sorted(solver_df['n_refinements'].unique())

        for refs in refs_list:
            ref_df = solver_df[solver_df['n_refinements'] == refs].sort_values('n_mpi')
            if len(ref_df) < 2:
                continue

            label = f"{solver.replace('_', '-')} (refs={refs})"
            color = colors[solver]
            marker = markers[solver]
            alpha = 0.4 + 0.2 * (refs - min(refs_list))

            cores = ref_df['n_mpi'].values

            baseline_solve = ref_df['solve_time_avg'].iloc[0]
            speedup = baseline_solve / ref_df['solve_time_avg']
            efficiency = speedup / (cores / cores[0])
            throughput = ref_df['n_dofs'].iloc[0] / ref_df['solve_time_avg']

            axes[0, 0].plot(cores, ref_df['solve_time_avg'], f'{marker}-',
                          label=label, color=color, alpha=alpha, markersize=6)
            axes[0, 1].plot(cores, speedup, f'{marker}-',
                          label=label, color=color, alpha=alpha, markersize=6)
            axes[1, 0].plot(cores, efficiency, f'{marker}-',
                          label=label, color=color, alpha=alpha, markersize=6)
            axes[1, 1].plot(cores, throughput, f'{marker}-',
                          label=label, color=color, alpha=alpha, markersize=6)

    max_cores = strong_df['n_mpi'].max()
    axes[0, 1].plot([1, max_cores], [1, max_cores], 'k--', lw=2, label='Ideal')
    axes[1, 0].axhline(y=1.0, color='k', linestyle='--', lw=2, label='Ideal (100%)')

    axes[0, 0].set_xlabel('MPI Processes')
    axes[0, 0].set_ylabel('Solve Time (s)')
    axes[0, 0].set_title('Strong Scaling: Solve Time\n(Pure MPI, 1 thread/process)')
    axes[0, 0].legend(fontsize=8)
    axes[0, 0].set_xscale('log', base=2)
    axes[0, 0].set_yscale('log')

    axes[0, 1].set_xlabel('MPI Processes')
    axes[0, 1].set_ylabel('Speedup')
    axes[0, 1].set_title('Strong Scaling: Speedup')
    axes[0, 1].legend(fontsize=8)
    axes[0, 1].set_xscale('log', base=2)
    axes[0, 1].set_yscale('log', base=2)

    axes[1, 0].set_xlabel('MPI Processes')
    axes[1, 0].set_ylabel('Parallel Efficiency')
    axes[1, 0].set_title('Strong Scaling: Efficiency')
    axes[1, 0].legend(fontsize=8)
    axes[1, 0].set_xscale('log', base=2)
    axes[1, 0].set_ylim([0, 1.2])

    axes[1, 1].set_xlabel('MPI Processes')
    axes[1, 1].set_ylabel('DoFs/second')
    axes[1, 1].set_title('Strong Scaling: Throughput')
    axes[1, 1].legend(fontsize=8)
    axes[1, 1].set_xscale('log', base=2)
    axes[1, 1].set_yscale('log')

    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'strong_scaling_pure_mpi.png'))
    plt.close()
    print("Saved: strong_scaling_pure_mpi.png")

def plot_weak_scaling(df, output_dir):
    fig, axes = plt.subplots(1, 2, figsize=(12, 5))

    weak_df = df[df['test_type'] == 'weak_scaling'].copy()
    if weak_df.empty:
        print("No weak scaling data")
        return

    weak_df = weak_df[weak_df['n_threads'] == 1]

    for solver in ['matrix_based', 'matrix_free']:
        solver_df = weak_df[weak_df['solver_type'] == solver].sort_values('n_mpi')
        if solver_df.empty:
            continue

        color = 'tab:blue' if solver == 'matrix_based' else 'tab:orange'
        marker = 'o' if solver == 'matrix_based' else 's'
        label = solver.replace('_', '-')

        axes[0].plot(solver_df['n_mpi'], solver_df['solve_time_avg'],
                    f'{marker}-', label=label, color=color, markersize=8)

        if len(solver_df) > 0:
            baseline = solver_df['solve_time_avg'].iloc[0]
            efficiency = baseline / solver_df['solve_time_avg']
            axes[1].plot(solver_df['n_mpi'], efficiency,
                        f'{marker}-', label=label, color=color, markersize=8)

    axes[0].set_xlabel('MPI Processes')
    axes[0].set_ylabel('Solve Time (s)')
    axes[0].set_title('Weak Scaling: Solve Time\n(should be constant for ideal scaling)')
    axes[0].legend()
    axes[0].set_xscale('log', base=2)

    axes[1].axhline(y=1.0, color='k', linestyle='--', lw=2, label='Ideal')
    axes[1].set_xlabel('MPI Processes')
    axes[1].set_ylabel('Efficiency = T(1)/T(p)')
    axes[1].set_title('Weak Scaling: Efficiency')
    axes[1].legend()
    axes[1].set_xscale('log', base=2)
    axes[1].set_ylim([0, 1.5])

    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'weak_scaling.png'))
    plt.close()
    print("Saved: weak_scaling.png")

def print_summary(df):
    print("\n" + "="*70)
    print("DATA SUMMARY")
    print("="*70)
    print(f"Total records: {len(df)}")
    print(f"Solvers: {df['solver_type'].unique().tolist()}")
    print(f"Test types: {df['test_type'].unique().tolist()}")

    print("\nStrong scaling (pure MPI) summary:")
    strong_mpi = df[(df['test_type'] == 'strong_scaling') & (df['n_threads'] == 1)]
    for solver in strong_mpi['solver_type'].unique():
        solver_df = strong_mpi[strong_mpi['solver_type'] == solver]
        for refs in sorted(solver_df['n_refinements'].unique()):
            ref_df = solver_df[solver_df['n_refinements'] == refs].sort_values('n_mpi')
            if len(ref_df) >= 2:
                t1 = ref_df['solve_time_avg'].iloc[0]
                tn = ref_df['solve_time_avg'].iloc[-1]
                n1 = ref_df['n_mpi'].iloc[0]
                nn = ref_df['n_mpi'].iloc[-1]
                speedup = t1 / tn
                ideal = nn / n1
                eff = speedup / ideal * 100
                print(f"  {solver} refs={refs}: T({n1})={t1:.3f}s -> T({nn})={tn:.3f}s, "
                      f"Speedup={speedup:.1f}x (ideal={ideal:.0f}x), Eff={eff:.0f}%")

def main():
    if len(sys.argv) < 2:
        print("Usage: python analyze_scaling.py <results_csv>")
        sys.exit(1)

    csv_file = sys.argv[1]
    output_dir = os.path.dirname(csv_file) or '.'

    print(f"Loading: {csv_file}")
    df = load_data(csv_file)

    print_summary(df)

    print("\nGenerating plots...")
    plot_strong_scaling_pure_mpi(df, output_dir)
    plot_weak_scaling(df, output_dir)

    print("\nDone!")

if __name__ == "__main__":
    main()
PYTHON_EOF

chmod +x ${ANALYSIS_SCRIPT}

#===============================================================================
# Final Summary
#===============================================================================

echo ""
echo "==============================================================================="
echo "BENCHMARK COMPLETE"
echo "==============================================================================="
echo "Results: ${RESULTS_DIR}"
echo ""
echo "Key output files:"
echo "  ${COMBINED_ALL}          - All results combined"
echo ""
echo "To generate plots:"
echo "  python ${ANALYSIS_SCRIPT} ${COMBINED_ALL}"
echo ""
echo "End: $(date)"
echo "==============================================================================="
